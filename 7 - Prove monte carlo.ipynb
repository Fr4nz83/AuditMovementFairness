{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auditing a Classifier for Fairness Based on Movement Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aux functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_lists_ids(np_list_candidates : np.ndarray) -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    ''' \n",
    "    Flatten the object ID lists associated with the candidates into a 1D array ###\n",
    "    # NOTE: we do this because we can then use joblib's shared memory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    np_list_candidates : np.ndarray\n",
    "        An array of lists, where each list contains the object IDs associated with a candidate.\n",
    "    labels : np.ndarray\n",
    "        A binary array indicating the presence (1) or absence (0) of a certain property for a given set of objects.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    flat_ids : np.ndarray\n",
    "        A 1D array containing all the object IDs associated with the candidates, concatenated together.\n",
    "    indptr : np.ndarray\n",
    "        An array of indices indicating the starting position of each candidate's list in the `flat_ids` array.\n",
    "    lens : np.ndarray\n",
    "        An array containing the length of each candidate's list of associated object IDs.\n",
    "    '''\n",
    "\n",
    "    # Compute the lengths of each candidate's list.\n",
    "    lens = np.fromiter((a.size for a in np_list_candidates),\n",
    "                       dtype=np.int32, count=len(np_list_candidates))\n",
    "\n",
    "    # Compute the starting/ending positions of each candidate's list in the flattened array.\n",
    "    indptr = np.empty(lens.size + 1, dtype=np.uint32)\n",
    "    indptr[0] = 0\n",
    "    np.cumsum(lens, out=indptr[1:])\n",
    "\n",
    "    # Flatten the lists into a single vector.\n",
    "    flat_ids = np.concatenate(np_list_candidates).astype(np.uint32, copy=False)\n",
    "    \n",
    "    return flat_ids, indptr, lens\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main code\n",
    "\n",
    "Read the dataset with the objects' labels.\n",
    "**TODO**: we are using dummy labels for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset containing the true labels of the objects.\n",
    "n_objects = 100000\n",
    "positive_rate = 0.6\n",
    "labels = np.random.binomial(n=1, p=positive_rate, size=n_objects).astype(np.int8)\n",
    "# labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a single numpy vector contaning the candidates of all the grids. Then, flatten the lists in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_candidates = './data_simulator/huge_dataset/gencand/'\n",
    "list_candidates_paths = [f for f in Path(path_candidates).iterdir() if f.is_file()]\n",
    "\n",
    "# Read the candidates to be tested over a set of grids.\n",
    "np_list_candidates = None\n",
    "for path_candidates in tqdm(list_candidates_paths, \n",
    "                            desc=\"Processing candidate files\",\n",
    "                            unit=\"file\"):\n",
    "\n",
    "    # Read the candidates that have been generated for a specific grid.\n",
    "    candidates = pd.read_pickle(path_candidates)\n",
    "    # print(f\"Reading grid candidates from {path_candidates}\")\n",
    "\n",
    "    # Generate two numpy arrays from the candidates DataFrame: one for the list of users associated with each candidate\n",
    "    # (subset of cells), and one for the size (number of cells of a subset) of each candidate.\n",
    "    cand = candidates['list_users'].to_numpy()\n",
    "    np_list_candidates = np.append(np_list_candidates, cand) if np_list_candidates is not None else cand\n",
    "\n",
    "    # print(f\"Number of candidates: {cand.size}\")\n",
    "\n",
    "print(f\"Total number of candidates: {np_list_candidates.size}\")\n",
    "\n",
    "\n",
    "### Flatten the object ID lists associated with the candidates into a 1D array (plus aux arrays) ###\n",
    "flat_ids, indptr, lens = flatten_lists_ids(np_list_candidates)\n",
    "del np_list_candidates  # free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform the Monte Carlo simulations needed to determine the distribution of the test statistics under the assumption that the null hypothesis is true.\n",
    " \n",
    "The test statistics used is the maximum likelihood ratio computed across the regions of all the grids, while the likelihood function is the binomial-based one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import xlogy, xlog1py\n",
    "\n",
    "def batch_max_likelihood_ratio(labels_objects: np.ndarray, \n",
    "                               flat_ids: np.ndarray, indptr: np.ndarray, lens: np.ndarray,\n",
    "                               tot_sum_labels: int,\n",
    "                               logL0_max: float) -> tuple[np.ndarray, np.ndarray, np.ndarray, float]:\n",
    "    \n",
    "\n",
    "    # Gather labels for all ids, then sum per candidate via segmented reduction.\n",
    "    flat_vals = labels_objects[flat_ids]\n",
    "    inside_sum = np.add.reduceat(flat_vals, indptr[:-1]).astype(np.float32, copy=False)\n",
    "\n",
    "\n",
    "    # Vectorized computation: for each candidate subset of cells, compute the positive rate of the objects\n",
    "    # associated with the subset vs the positive rate of the other objects.\n",
    "    # NOTE: we use np.divide with the `where` parameter to avoid divisions by zero.\n",
    "    p, n = inside_sum, lens\n",
    "    P, N = tot_sum_labels, labels_objects.size\n",
    "    inside_positive_rate  = np.divide(p, n, out=np.zeros_like(p, dtype=np.float32), where=(n > 0))\n",
    "    outside_positive_rate = np.divide(P - p, N - n, out=np.zeros_like(p, dtype=np.float32), where=((N - n) > 0))\n",
    "    \n",
    "\n",
    "    # Unsafe computation of the log-likelihood under the alternative hypotesis.\n",
    "    #logL1 = (p * np.log(inside_positive_rate)\n",
    "    #         + (n - p) * np.log1p(-inside_positive_rate)\n",
    "    #         + (P - p) * np.log(outside_positive_rate)\n",
    "    #         + (N - n - (P - p)) * np.log1p(-outside_positive_rate))\n",
    "    \n",
    "    \n",
    "    # Safe alternative computation of the log-L1 via scipy functions. \n",
    "    # NOTE: the log-likelihood is -inf when the positive rate is 0 or 1, which can happen when p==0 or p==n for the inside positive rate, \n",
    "    # or when P-p==0 or N-n-(P-p)==0 for the outside positive rate. This is not a problem per se, since we are interested in the likelihood\n",
    "    # ratio, and if the likelihood under the alternative hypotesis is -inf, then the likelihood ratio will be 0, which is what we expect in\n",
    "    # these cases.\n",
    "    \n",
    "    # valid = (n > 0) & (n < N) # optional: mask degenerate windows (n==0 or n==N)\n",
    "    # logL1 = np.full_like(inside_positive_rate, -np.inf, dtype=np.float32)\n",
    "    logL1 = ( xlogy(p, inside_positive_rate) +                          # p * np.log(inside_positive_rate)\n",
    "              xlog1py((n - p), -inside_positive_rate) +                 # + (n - p) * np.log1p(-inside_positive_rate)\n",
    "              xlogy((P - p), outside_positive_rate) +                   # + (P - p) * np.log(outside_positive_rate)\n",
    "              xlog1py((N - n - (P - p)), -outside_positive_rate) )      # + (N - n - (P - p)) * np.log1p(-outside_positive_rate))\n",
    "\n",
    "    # Vectorized computation of the log-likelihood ratio of the candidates\n",
    "    logLR = logL1 - logL0_max\n",
    "    maxLogLR = float(np.nanmax(logLR)) \n",
    "\n",
    "    return inside_positive_rate, outside_positive_rate, logLR, maxLogLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = labels.sum(dtype=np.uint32) # Constant across permutations\n",
    "N = labels.size\n",
    "\n",
    "\n",
    "# Compute the L_0 likelihood, which models the likelihood of observing some data under the null hypotesis H_0, according to which there\n",
    "# is a single global distribution that governs the labels. It is constant across permutations since it depends only on the total number\n",
    "# of positive and negative labels in the dataset, which are not changed by shuffling the labels.\n",
    "rho = P / N\n",
    "logL0_max = P * np.log(rho) + (N - P) * np.log1p(-rho)\n",
    "\n",
    "\n",
    "num_simulations = 200\n",
    "vec_max_LR = np.empty(num_simulations, dtype=np.float32)\n",
    "for i in tqdm(range(num_simulations)):    \n",
    "    # Shuffle the original labels assigned to the objects. This represents the null hypotesis H_0, according to which\n",
    "    # there is a single global distribution that governs the labels, i.e., there is not one or more sets of geographical regions\n",
    "    # in which the associated objects have an average positive rate that is significantly different than that of the other objects. \n",
    "    rng = np.random.default_rng(i)\n",
    "    shuffled_labels = rng.permutation(labels)\n",
    "\n",
    "    # For the objects associated with each subset of cells, compute their positive rate vs that of the other objects.\n",
    "    _, _, _, vec_max_LR[i] = batch_max_likelihood_ratio(shuffled_labels,\n",
    "                                                        flat_ids, indptr, lens,\n",
    "                                                        P, logL0_max)\n",
    "\n",
    "\n",
    "# DEBUG\n",
    "# np_list_candidates_inrate, np_list_candidates_outrate\n",
    "\n",
    "# Print the most extreme likelihood ratio observed across all the simulations.\n",
    "display(np.sort(vec_max_LR)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the likelihood ratio of the candidates on the original labels.\n",
    "_, _, vec_LR_dataset, max_LR_dataset = batch_max_likelihood_ratio(labels,\n",
    "                                                                  flat_ids, indptr, lens,\n",
    "                                                                  P, logL0_max)\n",
    "max_LR_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEBUG: Simple for loop-based version of the computation of inside/outside positive rates; to be used for debugging purposes ###"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Simple for loop-based version ###\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def sequential_compute_in_out_probs(labels: np.ndarray, sel_ids: np.ndarray, \n",
    "                                    tot_num_els : int, tot_sum_labels : float) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    probs[i] = probability of object i\n",
    "    ids = iterable of object IDs (indices)\n",
    "\n",
    "    Returns:\n",
    "        (mean_inside, mean_outside)\n",
    "    \"\"\"\n",
    "\n",
    "    k = sel_ids.size\n",
    "    sum_inside = labels.take(sel_ids).sum(dtype=np.uint32)\n",
    "    mean_inside = float(sum_inside) / k\n",
    "    mean_outside = float(tot_sum_labels - sum_inside) / (tot_num_els - k)\n",
    "    \n",
    "    return mean_inside, mean_outside\n",
    "\n",
    "\n",
    "# Main code\n",
    "sum_all_labels = labels.sum()\n",
    "tot_num_labels = len(labels)\n",
    "list_mean_inside = []\n",
    "list_mean_outside = []\n",
    "for el in tqdm(candidates[\"list_users\"], total=len(candidates[\"list_users\"]), desc=\"Computing in/out probs\"):\n",
    "    # print(f\"Selected IDs: {sel_ids}\")\n",
    "    mean_inside, mean_outside = sequential_compute_in_out_probs(labels, el, tot_num_labels, sum_all_labels)\n",
    "    list_mean_inside.append(mean_inside)\n",
    "    list_mean_outside.append(mean_outside)\n",
    "    # print(f\"Positive rate inside: {mean_inside}, Positive rate outside: {mean_outside}\")\n",
    "\n",
    "candidates[\"in_rate_debug\"], candidates[\"out_rate_debug\"] = list_mean_inside, list_mean_outside"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
