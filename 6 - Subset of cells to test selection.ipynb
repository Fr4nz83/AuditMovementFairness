{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbcaf7c-64f4-41fe-b59c-647fa3fddd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from src.grid_partitioning import Grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12c9d1d-dbd8-46bd-a408-b343e6927819",
   "metadata": {},
   "source": [
    "### Main code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b905fba",
   "metadata": {},
   "source": [
    "Read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd059a8-2d5d-4300-9a63-ab29d6dae830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the files needed in input\n",
    "path_users_classification = './data_simulator/huge_dataset/dataset_simulator_trajectories.compressed.parquet.classified.parquet'\n",
    "path_users_cells_mapping = './mapping_users_cells_grid_50m.pkl'\n",
    "\n",
    "users_labels = pd.read_parquet(path_users_classification)\n",
    "display(users_labels)\n",
    "\n",
    "mapping_users_cells = pd.DataFrame(pd.read_pickle(path_users_cells_mapping))\n",
    "display(mapping_users_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5ff090",
   "metadata": {},
   "source": [
    "### Various operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03b13c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that we are dealing with the classification case, and that the labels follow a Bernoullian distribution, \n",
    "# determine the global positive and negative rates on the users labels.\n",
    "global_positive_rate = users_labels['label'].mean()\n",
    "global_negative_rate = 1 - global_positive_rate\n",
    "print(f\"Global positive rate: {global_positive_rate} - global negative rate: {global_negative_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493988e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the labels to the dataframe that maps 'users to cells'.\n",
    "mapping_users_cells['label'] = users_labels['label']\n",
    "display(mapping_users_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a033c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a more compact indexing for the cell IDs: these IDs can have gaps in them, so reindex their IDs\n",
    "# to prepare more efficient set intersections over the user IDs they refer to.\n",
    "array_cell_ids = np.sort(mapping_users_cells['cell_id'].unique())\n",
    "remapping_indices_cells = pd.Series(index = array_cell_ids, data = range(len(array_cell_ids)))\n",
    "del array_cell_ids\n",
    "display(remapping_indices_cells)\n",
    "\n",
    "# Produce a more compact indexing for the user IDs. Same reason as above.\n",
    "array_user_ids = np.sort(mapping_users_cells.index.unique())\n",
    "remapping_indices_users = pd.Series(index = array_user_ids, data = range(len(array_user_ids)))\n",
    "del array_user_ids\n",
    "display(remapping_indices_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c25d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "remapping_users_cells = mapping_users_cells.copy(deep=True)\n",
    "\n",
    "# Remap cell and user IDs to comntinous ranges.\n",
    "remapping_users_cells.index = remapping_users_cells.index.map(remapping_indices_users)\n",
    "display(remapping_users_cells)\n",
    "remapping_users_cells['cell_id'] = remapping_users_cells['cell_id'].map(remapping_indices_cells)\n",
    "display(remapping_users_cells)\n",
    "\n",
    "# Regenerate the mapping between users-labels.\n",
    "remapping_users_labels = remapping_users_cells.groupby('uid')['label'].first()\n",
    "display(remapping_users_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8cbb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute some aggregations at cell-level, effectively creating an augmented version of the grid. \n",
    "stats_config = {'list_users' : pd.NamedAgg(column='uid', aggfunc=set),\n",
    "                'num_users' : pd.NamedAgg(column='uid', aggfunc='nunique'),\n",
    "                'positive_rate' : pd.NamedAgg(column='label', aggfunc='mean')}\n",
    "aug_grid = (remapping_users_cells.reset_index()\n",
    "                                 .groupby('cell_id')\n",
    "                                 .agg(**stats_config))\n",
    "aug_grid['negative_rate'] = 1 - aug_grid['positive_rate']\n",
    "\n",
    "\n",
    "# Sort the cells by their IDs.\n",
    "aug_grid.sort_values(by='cell_id', ascending=True, inplace=True)\n",
    "display(aug_grid)\n",
    "display(aug_grid.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95da6fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versione Python non ottimizzata intersezione liste ID utenti celle.\n",
    "from itertools import combinations\n",
    "\n",
    "intersections = {}\n",
    "cnt_threshold = 5\n",
    "pairs = list(zip(aug_grid.index, aug_grid['list_users']))\n",
    "for (cell_id, list_users), (other_cell_id, other_list_users) in combinations(pairs, 2):\n",
    "    \n",
    "    # Compute the set intersection, and its cardinality.\n",
    "    intersection = list_users & other_list_users\n",
    "    cnt = len(intersection)\n",
    "\n",
    "    # Add to the dictionary only the cell pairs that have at least 'threshold' users in common.\n",
    "    # The threshold should be calculated according to the statistical power we want to have in the hypotesis tests.\n",
    "    if cnt > cnt_threshold :\n",
    "        intersections[(cell_id, other_cell_id)] = intersection\n",
    "\n",
    "\n",
    "# Store the results of the set intersections in a pandas Dataframe.\n",
    "testa = pd.Series(data = intersections, name='set_intersection').to_frame()\n",
    "del intersections\n",
    "\n",
    "display(testa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eee0202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to compute the local positive rate of the various combinations of cells...\n",
    "\n",
    "# 1 - turn each user ID in a list element into a row.\n",
    "tmp = testa.explode('set_intersection', ignore_index=False)\n",
    "display(tmp)\n",
    "\n",
    "# 2 - For every user ID, find the associated predicted label.\n",
    "tmp['set_intersection'] = tmp['set_intersection'].map(remapping_users_labels)\n",
    "display(tmp)\n",
    "\n",
    "# 3- For every combination of cells found in tmp's index, compute the local positive rate.\n",
    "testa['positive_rate'] = tmp.groupby(level=list(range(tmp.index.nlevels)))['set_intersection'].mean()\n",
    "del tmp\n",
    "\n",
    "display(testa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ffcd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add to the list of combinations  of cell to check those whose positive rate differs more than\n",
    "#       some threshold from the global one.\n",
    "eps = global_positive_rate / 10\n",
    "testa[abs(testa['positive_rate'] - global_positive_rate) > eps].index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
